# Breeze-ASR-25 最佳化版本使用指南

## 🎯 版本特色

### 結合兩個版本的優勢
- **train.py 的記憶體效率**: 即時轉換、多進程載入
- **finetune_Breeze_whisper.py 的功能性**: 完整的 Breeze 模型支援
- **針對 RTX 3060 Ti 8GB 優化**: 確保穩定運行

## 📋 系統需求

### 硬體需求
- **GPU**: NVIDIA RTX 3060 Ti (8GB VRAM) 或更高
- **CPU**: AMD Ryzen 5 3600 或更高
- **記憶體**: 32GB RAM (建議)
- **硬碟**: 至少 20GB 可用空間

### 軟體需求
- **Python**: 3.8+
- **CUDA**: 11.0+
- **PyTorch**: 2.0+
- **Transformers**: 4.30+

## 🚀 使用方法

### 1. 環境準備
```bash
# 啟動虛擬環境
.venv\Scripts\activate

# 安裝依賴 (如果需要)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install transformers datasets librosa jiwer tensorboard
```

### 2. 資料準備
確保您有以下檔案：
- `metadata_train.csv`: 訓練資料
- `metadata_test.csv`: 測試資料

**必要欄位**:
- `file`: 音訊檔案路徑
- `中文意譯`: 對應的中文文字

### 3. 開始訓練
```bash
# 單獨運行
python finetune_Breeze_optimal.py

# 同時監控 (建議)
# 終端 1: 訓練
python finetune_Breeze_optimal.py

# 終端 2: 監控
python monitor_training.py

# 終端 3: TensorBoard
tensorboard --logdir ./breeze-asr-25-optimal/runs
```

## ⚙️ 配置說明

### 記憶體優化配置
```python
# 極小批次大小確保穩定
per_device_train_batch_size=2
per_device_eval_batch_size=2

# 大梯度累積維持訓練效果
gradient_accumulation_steps=8  # 有效批次 = 2*8 = 16

# FP16 節省記憶體
fp16=True

# 關閉梯度檢查點避免相容性問題
gradient_checkpointing=False
```

### 訓練穩定性配置
```python
# 保守的學習率
learning_rate=1e-5

# 限制訓練步數
max_steps=5000

# 頻繁評估和保存
eval_steps=500
save_steps=500

# 早停機制
early_stopping_patience=3
```

### 效能優化配置
```python
# 即時資料轉換
vectorized_datasets = dataset_split.with_transform(prepare_fn)

# 多進程載入
dataloader_num_workers=2

# 生成模式評估
predict_with_generate=True
generation_max_length=448
```

## 📊 預期效能

### 記憶體使用
- **GPU 記憶體**: 3-5GB (遠低於 8GB 限制)
- **系統記憶體**: 8-12GB
- **硬碟空間**: 模型檢查點約 5GB

### 訓練時間
- **總訓練時間**: 3-5 小時 (5000 步)
- **每步時間**: 2-3 秒
- **評估時間**: 5-10 分鐘 (每 500 步)

### 預期結果
- **WER**: 目標 < 20% (取決於資料品質)
- **CER**: 目標 < 15%
- **訓練穩定性**: 高 (無 OOM 風險)

## 🔧 故障排除

### 常見問題及解決方案

#### 1. CUDA 記憶體不足
```bash
# 檢查 GPU 狀態
nvidia-smi

# 如果仍然 OOM，進一步降低批次大小
per_device_train_batch_size=1
gradient_accumulation_steps=16
```

#### 2. 多進程錯誤
```python
# 如果 Windows 多進程有問題，設為 0
dataloader_num_workers=0
```

#### 3. 資料載入錯誤
```python
# 檢查資料路徑和格式
print(train_df.head())
print(train_df.columns)
```

#### 4. 模型載入失敗
```bash
# 檢查網路連接和 HuggingFace 存取
huggingface-cli login
```

## 📈 監控和評估

### TensorBoard 監控
```bash
# 啟動 TensorBoard
tensorboard --logdir ./breeze-asr-25-optimal/runs

# 瀏覽器開啟
http://localhost:6006
```

### 關鍵指標
- **訓練損失**: 應該持續下降
- **評估 WER**: 應該持續改善
- **學習率**: 按調度器變化
- **GPU 記憶體**: 穩定在 3-5GB

### 日誌檔案
- **訓練日誌**: `./breeze-asr-25-optimal/logs/`
- **檢查點**: `./breeze-asr-25-optimal/checkpoint-*/`
- **最終模型**: `./breeze-asr-25-optimal/`

## 🎯 最佳實踐

### 1. 訓練前準備
- 確保資料品質良好
- 檢查音訊檔案完整性
- 驗證文字標籤正確性

### 2. 訓練期間
- 定期檢查 TensorBoard
- 監控 GPU 記憶體使用
- 觀察 WER 變化趨勢

### 3. 訓練後處理
- 保存最佳模型
- 進行額外的測試評估
- 記錄訓練參數和結果

## 🔄 進階調整

### 根據結果調整參數

#### 如果訓練太慢
```python
# 增加批次大小 (如果記憶體允許)
per_device_train_batch_size=4
gradient_accumulation_steps=4

# 增加 workers
dataloader_num_workers=4
```

#### 如果 WER 不夠好
```python
# 增加訓練步數
max_steps=10000

# 降低學習率
learning_rate=5e-6

# 增加預熱步數
warmup_steps=1000
```

#### 如果過擬合
```python
# 增加權重衰減
weight_decay=0.05

# 增加 dropout (需要修改模型配置)
# 或使用資料增強
```

這個最佳化版本結合了兩個版本的優勢，應該能在您的硬體上穩定高效地運行，並獲得良好的訓練結果！ 