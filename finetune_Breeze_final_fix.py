# ==============================================================================
# æª”æ¡ˆï¼šfinetune_Breeze_final_fix.py
# æè¿°ï¼šä¿®å¾© FP16 æ¢¯åº¦å•é¡Œçš„æœ€çµ‚ç©©å®šç‰ˆæœ¬
# æ ¸å¿ƒç­–ç•¥ï¼š
# 1. ä½¿ç”¨ FP32 ç²¾åº¦é¿å…æ¢¯åº¦ç¸®æ”¾å•é¡Œ
# 2. ä¿æŒæ¥µå°æ‰¹æ¬¡å¤§å°ç¢ºä¿è¨˜æ†¶é«”å®‰å…¨
# 3. å„ªåŒ–çš„è¨“ç·´é…ç½®ç¢ºä¿ç©©å®šæ€§
# ==============================================================================

import gc
import os
import warnings
from dataclasses import dataclass
from functools import partial
from typing import Any, Dict, List, Union

import evaluate
import pandas as pd
import torch

# è¨­å®šç’°å¢ƒè®Šæ•¸
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

from datasets import Audio, Dataset

# --- Hugging Face ç›¸é—œå°å…¥ ---
from transformers import (
    Seq2SeqTrainer,
    Seq2SeqTrainingArguments,
    WhisperFeatureExtractor,
    WhisperForConditionalGeneration,
    WhisperProcessor,
    WhisperTokenizer,
)

# ==============================================================================
# è¨˜æ†¶é«”ç®¡ç†å·¥å…·
# ==============================================================================


def cleanup_memory():
    """è¨˜æ†¶é«”æ¸…ç†"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    print("ğŸ§¹ è¨˜æ†¶é«”æ¸…ç†å®Œæˆ")


def check_memory():
    """æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / (1024**3)
        reserved = torch.cuda.memory_reserved() / (1024**3)
        total = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        print(
            f"ğŸ’¾ è¨˜æ†¶é«”ï¼š{allocated:.2f}GB åˆ†é… / {reserved:.2f}GB ä¿ç•™ / {total:.2f}GB ç¸½è¨ˆ"
        )


# ==============================================================================
# è³‡æ–™è™•ç†çµ„ä»¶
# ==============================================================================


@dataclass
class SimpleDataCollator:
    """ç°¡åŒ–çš„ Data Collator"""

    processor: Any

    def __call__(
        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]
    ) -> Dict[str, torch.Tensor]:
        # è™•ç†è¼¸å…¥ç‰¹å¾µ
        input_features = [
            {"input_features": feature["input_features"]} for feature in features
        ]
        batch = self.processor.feature_extractor.pad(
            input_features, return_tensors="pt"
        )

        # è™•ç†æ¨™ç±¤
        label_features = [{"input_ids": feature["labels"]} for feature in features]
        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors="pt")

        labels = labels_batch["input_ids"].masked_fill(
            labels_batch.attention_mask.ne(1), -100
        )

        # ç§»é™¤ BOS token
        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():
            labels = labels[:, 1:]

        batch["labels"] = labels
        return batch


def prepare_dataset_simple(batch, feature_extractor, tokenizer):
    """ç°¡åŒ–çš„è³‡æ–™é è™•ç†"""
    audio_list = batch["audio"]

    # è™•ç†éŸ³è¨Šç‰¹å¾µ
    input_features = feature_extractor(
        [x["array"] for x in audio_list], sampling_rate=audio_list[0]["sampling_rate"]
    ).input_features

    # è™•ç†æ¨™ç±¤
    labels = tokenizer(
        batch["transcription"], max_length=448, truncation=True
    ).input_ids

    return {"input_features": input_features, "labels": labels}


def compute_metrics_simple(pred, tokenizer):
    """ç°¡åŒ–çš„æŒ‡æ¨™è¨ˆç®—"""
    try:
        pred_ids = pred.predictions
        label_ids = pred.label_ids

        label_ids[label_ids == -100] = tokenizer.pad_token_id

        pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)
        label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)

        metric = evaluate.load("wer")
        wer = 100 * metric.compute(predictions=pred_str, references=label_str)

        return {"wer": wer}
    except Exception as e:
        print(f"âš ï¸ æŒ‡æ¨™è¨ˆç®—éŒ¯èª¤ï¼š{e}")
        return {"wer": 100.0}


# ==============================================================================
# è³‡æ–™é›†è™•ç†å™¨
# ==============================================================================


class SimpleDatasetProcessor:
    """ç°¡åŒ–çš„è³‡æ–™é›†è™•ç†å™¨"""

    def __init__(
        self,
        file_path: str,
        target_sampling_rate: int = 16000,
        subset_fraction: float = 0.01,
    ):
        self.file_path = file_path
        self.target_sampling_rate = target_sampling_rate
        self.subset_fraction = subset_fraction

    def create_dataset(self) -> Dataset:
        print(f"è¼‰å…¥è³‡æ–™æª”æ¡ˆï¼š{self.file_path}")

        try:
            df = pd.read_csv(self.file_path)
        except FileNotFoundError:
            print("âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼Œå˜—è©¦ä½¿ç”¨å‚™ç”¨è·¯å¾‘...")
            alternative_path = "output/final_audio_paths_zh.csv"
            df = pd.read_csv(alternative_path)
            print(f"âœ… ä½¿ç”¨å‚™ç”¨æª”æ¡ˆï¼š{alternative_path}")

        # ä½¿ç”¨æ¥µå°çš„è³‡æ–™å­é›†
        subset_size = max(20, int(len(df) * self.subset_fraction))  # è‡³å°‘ 20 å€‹æ¨£æœ¬
        print(f"å®Œæ•´è³‡æ–™é›†å¤§å°ï¼š{len(df)}")
        print(f"ä½¿ç”¨è³‡æ–™é›†å¤§å°ï¼š{subset_size} ({(subset_size/len(df)*100):.1f}%)")

        # éš¨æ©Ÿå–æ¨£
        subset_data = df.sample(n=subset_size, random_state=42).reset_index(drop=True)

        dataset = Dataset.from_pandas(subset_data)
        dataset = dataset.cast_column(
            "file", Audio(sampling_rate=self.target_sampling_rate)
        )
        dataset = dataset.rename_column("file", "audio")

        return dataset


# ==============================================================================
# ä¸»åŸ·è¡Œæµç¨‹
# ==============================================================================


def main():
    print("=== Breeze ASR æœ€çµ‚ä¿®å¾©ç‰ˆæœ¬ ===")
    print("ğŸ”§ ä¿®å¾© FP16 æ¢¯åº¦å•é¡Œ")

    # --- åƒæ•¸è¨­å®š ---
    CSV_PATH = "output_zh_optimized_v2.csv"
    MODEL_NAME = "MediaTek-Research/Breeze-ASR-25"
    LANGUAGE = "zh"
    TASK = "transcribe"
    OUTPUT_DIR = "./whisper-small-zh-finetune-final"

    print(f"æ¨¡å‹ï¼š{MODEL_NAME}")
    print(f"è¼¸å‡ºç›®éŒ„ï¼š{OUTPUT_DIR}")

    # åˆå§‹æ¸…ç†
    cleanup_memory()
    check_memory()

    try:
        # --- è¼‰å…¥ Processor å’Œæ¨¡å‹ ---
        print("\n--- æ­¥é©Ÿ 1/4: è¼‰å…¥ Processor å’Œæ¨¡å‹ ---")
        processor = WhisperProcessor.from_pretrained(
            MODEL_NAME, language=LANGUAGE, task=TASK
        )
        print("âœ… Processor è¼‰å…¥æˆåŠŸ")

        # è¼‰å…¥æ¨¡å‹ï¼ˆä½¿ç”¨ FP32 é¿å…æ¢¯åº¦å•é¡Œï¼‰
        model = WhisperForConditionalGeneration.from_pretrained(
            MODEL_NAME,
            torch_dtype=torch.float32,  # ä½¿ç”¨ FP32 é¿å…æ¢¯åº¦ç¸®æ”¾å•é¡Œ
            device_map="auto",
            low_cpu_mem_usage=True,
        )
        print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼ˆFP32 æ¨¡å¼ï¼‰")

        # é…ç½®æ¨¡å‹
        model.config.forced_decoder_ids = None
        model.config.suppress_tokens = []

        check_memory()

        # --- å»ºç«‹è³‡æ–™é›† ---
        print("\n--- æ­¥é©Ÿ 2/4: å»ºç«‹è³‡æ–™é›† (1% è³‡æ–™) ---")
        audio_processor = SimpleDatasetProcessor(
            file_path=CSV_PATH, subset_fraction=0.01  # ä½¿ç”¨ 1% çš„è³‡æ–™
        )

        dataset = audio_processor.create_dataset()
        print(f"è³‡æ–™é›†å»ºç«‹å®Œæˆï¼Œæ¨£æœ¬æ•¸ï¼š{len(dataset)}")

        # åˆ†å‰²è¨“ç·´å’Œæ¸¬è©¦é›†
        common_voice = dataset.train_test_split(test_size=0.2, seed=42)
        print(f"è¨“ç·´é›†ï¼š{len(common_voice['train'])} æ¨£æœ¬")
        print(f"æ¸¬è©¦é›†ï¼š{len(common_voice['test'])} æ¨£æœ¬")

        # è¨­å®šå³æ™‚è½‰æ›
        prepare_fn = partial(
            prepare_dataset_simple,
            feature_extractor=processor.feature_extractor,
            tokenizer=processor.tokenizer,
        )
        vectorized_datasets = common_voice.with_transform(prepare_fn)
        print("å³æ™‚è½‰æ›å·²è¨­å®š")

        check_memory()

        # --- å»ºç«‹è¨“ç·´å…ƒä»¶ ---
        print("\n--- æ­¥é©Ÿ 3/4: å»ºç«‹è¨“ç·´å…ƒä»¶ ---")
        data_collator = SimpleDataCollator(processor=processor)
        compute_metrics_fn = partial(
            compute_metrics_simple, tokenizer=processor.tokenizer
        )

        # ç©©å®šçš„è¨“ç·´åƒæ•¸ï¼ˆé—œéµï¼šä¸ä½¿ç”¨ FP16ï¼‰
        training_args = Seq2SeqTrainingArguments(
            output_dir=OUTPUT_DIR,
            # å°æ‰¹æ¬¡é…ç½®
            per_device_train_batch_size=1,
            per_device_eval_batch_size=1,
            gradient_accumulation_steps=4,
            # é—œé–‰å¤šé€²ç¨‹
            dataloader_num_workers=0,
            dataloader_pin_memory=False,
            # å­¸ç¿’åƒæ•¸
            learning_rate=1e-5,
            warmup_steps=5,
            max_steps=50,  # æ¥µå°‘æ­¥æ•¸ç¢ºä¿æˆåŠŸ
            # é—œéµï¼šä¸ä½¿ç”¨ FP16 ä»¥é¿å…æ¢¯åº¦ç¸®æ”¾å•é¡Œ
            fp16=False,  # è¨­ç‚º False é¿å…æ¢¯åº¦å•é¡Œ
            bf16=False,  # ä¹Ÿä¸ä½¿ç”¨ bf16
            # ç°¡åŒ–çš„è©•ä¼°å’Œä¿å­˜
            eval_strategy="steps",
            predict_with_generate=True,
            generation_max_length=128,
            save_steps=25,
            eval_steps=25,
            logging_steps=5,
            # é—œé–‰ä¸å¿…è¦çš„åŠŸèƒ½
            report_to=[],
            load_best_model_at_end=False,
            save_total_limit=1,
            # å…¶ä»–è¨­å®š
            remove_unused_columns=False,
            optim="adamw_torch",
            gradient_checkpointing=False,
        )

        # å»ºç«‹è¨“ç·´å™¨
        trainer = Seq2SeqTrainer(
            args=training_args,
            model=model,
            train_dataset=vectorized_datasets["train"],
            eval_dataset=vectorized_datasets["test"],
            data_collator=data_collator,
            compute_metrics=compute_metrics_fn,
            tokenizer=processor.feature_extractor,
        )

        check_memory()

        # --- é–‹å§‹è¨“ç·´ ---
        print("\n--- æ­¥é©Ÿ 4/4: é–‹å§‹æœ€çµ‚è¨“ç·´ ---")
        print("ğŸš€ é æœŸè¨“ç·´æ™‚é–“ï¼š3-5 åˆ†é˜")
        print("ğŸ’¡ ä½¿ç”¨ FP32 ç²¾åº¦ç¢ºä¿ç©©å®šæ€§")

        cleanup_memory()
        check_memory()

        # é–‹å§‹è¨“ç·´
        trainer.train()
        print("\nâœ… æœ€çµ‚è¨“ç·´å®Œæˆï¼")

        # --- å„²å­˜æ¨¡å‹ ---
        print("\n--- å„²å­˜æ¨¡å‹ ---")
        trainer.save_model(OUTPUT_DIR)
        processor.save_pretrained(OUTPUT_DIR)
        print(f"æ¨¡å‹å·²å„²å­˜è‡³ï¼š{OUTPUT_DIR}")

        # --- è¨“ç·´æ‘˜è¦ ---
        print("\n=== æœ€çµ‚è¨“ç·´æ‘˜è¦ ===")
        print(f"âœ… æˆåŠŸå®Œæˆè¨“ç·´ï¼")
        print(f"ä½¿ç”¨è³‡æ–™é‡ï¼š1% ({len(dataset)} æ¨£æœ¬)")
        print(f"è¨“ç·´æ­¥æ•¸ï¼š50 æ­¥")
        print(f"ç²¾åº¦æ¨¡å¼ï¼šFP32ï¼ˆç©©å®šï¼‰")
        print(f"æ‰¹æ¬¡è¨­å®šï¼šbatch_size=1, accumulation=4")
        print("ç‹€æ…‹ï¼šç„¡éŒ¯èª¤å®Œæˆ")

    except Exception as e:
        print(f"\nâŒ è¨“ç·´å¤±æ•—ï¼š{e}")
        print("\nğŸ”§ æ•…éšœæ’é™¤ï¼š")
        print("1. ç¢ºä¿æ²’æœ‰å…¶ä»–ç¨‹å¼ä½¿ç”¨ GPU")
        print("2. é‡å•Ÿ Python ç’°å¢ƒ")
        print("3. æª¢æŸ¥è³‡æ–™æª”æ¡ˆè·¯å¾‘")
        cleanup_memory()
        raise e

    finally:
        cleanup_memory()
        print("ğŸ§¹ æœ€çµ‚æ¸…ç†å®Œæˆ")


if __name__ == "__main__":
    main()
