# ==============================================================================
# æª”æ¡ˆï¼šfinetune_Breeze_memory_safe.py
# æè¿°ï¼šè¨˜æ†¶é«”å®‰å…¨çš„è¨“ç·´ç‰ˆæœ¬ï¼Œå¾¹åº•è§£æ±º CUDA OOM å•é¡Œ
# æ ¸å¿ƒç­–ç•¥ï¼š
# 1. æ¥µå°æ‰¹æ¬¡å¤§å° + å¤§æ¢¯åº¦ç´¯ç©
# 2. å¼·åˆ¶è¨˜æ†¶é«”æ¸…ç†å’Œç¢ç‰‡æ•´ç†
# 3. å„ªåŒ–çš„è³‡æ–™è¼‰å…¥å’Œæ¨¡å‹é…ç½®
# 4. éŒ¯èª¤æ¢å¾©æ©Ÿåˆ¶
# ==============================================================================

import gc
import os
import warnings
from dataclasses import dataclass
from functools import partial
from typing import Any, Dict, List, Union

import evaluate
import pandas as pd
import torch

# è¨­å®šç’°å¢ƒè®Šæ•¸ä»¥å„ªåŒ–è¨˜æ†¶é«”ç®¡ç†
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.environ["CUDA_LAUNCH_BLOCKING"] = "1"

from datasets import Audio, Dataset

# --- Hugging Face ç›¸é—œå°å…¥ ---
from transformers import (
    Seq2SeqTrainer,
    Seq2SeqTrainingArguments,
    WhisperFeatureExtractor,
    WhisperForConditionalGeneration,
    WhisperProcessor,
    WhisperTokenizer,
)

# ==============================================================================
# è¨˜æ†¶é«”ç®¡ç†å·¥å…·
# ==============================================================================


def aggressive_memory_cleanup():
    """æ¿€é€²çš„è¨˜æ†¶é«”æ¸…ç†"""
    import gc

    # Python åƒåœ¾å›æ”¶
    for _ in range(3):
        gc.collect()

    # CUDA è¨˜æ†¶é«”æ¸…ç†
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()

    print("ğŸ§¹ å®Œæˆæ¿€é€²è¨˜æ†¶é«”æ¸…ç†")


def check_memory_usage():
    """æª¢æŸ¥ä¸¦å ±å‘Šè¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / (1024**3)
        reserved = torch.cuda.memory_reserved() / (1024**3)
        max_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)

        print(
            f"ğŸ’¾ è¨˜æ†¶é«”ä½¿ç”¨ï¼š{allocated:.2f}GB åˆ†é… / {reserved:.2f}GB ä¿ç•™ / {max_memory:.2f}GB ç¸½è¨ˆ"
        )

        # å¦‚æœä½¿ç”¨è¶…é 80% è¨˜æ†¶é«”ï¼Œç™¼å‡ºè­¦å‘Š
        if allocated > max_memory * 0.8:
            print("âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨éé«˜ï¼ŒåŸ·è¡Œæ¸…ç†...")
            aggressive_memory_cleanup()


# ==============================================================================
# å„ªåŒ–çš„è³‡æ–™è™•ç†
# ==============================================================================


@dataclass
class MemorySafeDataCollator:
    """è¨˜æ†¶é«”å®‰å…¨çš„ Data Collator"""

    processor: Any

    def __call__(
        self, features: List[Dict[str, Union[List[int], torch.Tensor]]]
    ) -> Dict[str, torch.Tensor]:
        try:
            # è™•ç†è¼¸å…¥ç‰¹å¾µ
            input_features = [
                {"input_features": feature["input_features"]} for feature in features
            ]
            batch = self.processor.feature_extractor.pad(
                input_features, return_tensors="pt"
            )

            # è™•ç†æ¨™ç±¤
            label_features = [{"input_ids": feature["labels"]} for feature in features]
            labels_batch = self.processor.tokenizer.pad(
                label_features, return_tensors="pt"
            )

            labels = labels_batch["input_ids"].masked_fill(
                labels_batch.attention_mask.ne(1), -100
            )

            # ç§»é™¤ BOS token
            if (
                (labels[:, 0] == self.processor.tokenizer.bos_token_id)
                .all()
                .cpu()
                .item()
            ):
                labels = labels[:, 1:]

            batch["labels"] = labels

            # æ¸…ç†è‡¨æ™‚è®Šæ•¸
            del input_features, label_features, labels_batch

            return batch

        except Exception as e:
            print(f"âŒ DataCollator éŒ¯èª¤ï¼š{e}")
            aggressive_memory_cleanup()
            raise e


def prepare_dataset_memory_safe(batch, feature_extractor, tokenizer):
    """è¨˜æ†¶é«”å®‰å…¨çš„è³‡æ–™é è™•ç†"""
    try:
        audio_list = batch["audio"]

        # åˆ†æ‰¹è™•ç†éŸ³è¨Šä»¥ç¯€çœè¨˜æ†¶é«”
        input_features_list = []
        for audio in audio_list:
            features = feature_extractor(
                audio["array"],
                sampling_rate=audio["sampling_rate"],
                return_tensors="pt",
            )
            input_features_list.append(features.input_features[0])

        # åˆä½µç‰¹å¾µ
        batch["input_features"] = input_features_list

        # è™•ç†æ¨™ç±¤
        batch["labels"] = tokenizer(
            batch["transcription"], max_length=448, truncation=True
        ).input_ids

        # æ¸…ç†è‡¨æ™‚è®Šæ•¸
        del audio_list, input_features_list

        return batch

    except Exception as e:
        print(f"âŒ è³‡æ–™é è™•ç†éŒ¯èª¤ï¼š{e}")
        aggressive_memory_cleanup()
        raise e


def compute_metrics_safe(pred, tokenizer):
    """è¨˜æ†¶é«”å®‰å…¨çš„æŒ‡æ¨™è¨ˆç®—"""
    try:
        pred_ids = pred.predictions
        label_ids = pred.label_ids

        # è™•ç†æ¨™ç±¤
        label_ids[label_ids == -100] = tokenizer.pad_token_id

        # è§£ç¢¼
        pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)
        label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)

        # è¨ˆç®— WER
        metric = evaluate.load("wer")
        wer = 100 * metric.compute(predictions=pred_str, references=label_str)

        # æ¸…ç†
        del pred_ids, label_ids, pred_str, label_str

        return {"wer": wer}

    except Exception as e:
        print(f"âŒ æŒ‡æ¨™è¨ˆç®—éŒ¯èª¤ï¼š{e}")
        return {"wer": 100.0}


# ==============================================================================
# è¨˜æ†¶é«”å®‰å…¨çš„è³‡æ–™é›†è™•ç†å™¨
# ==============================================================================


class MemorySafeDatasetProcessor:
    """è¨˜æ†¶é«”å®‰å…¨çš„è³‡æ–™é›†è™•ç†å™¨"""

    def __init__(
        self,
        file_path: str,
        target_sampling_rate: int = 16000,
        subset_fraction: float = 0.02,
    ):
        self.file_path = file_path
        self.target_sampling_rate = target_sampling_rate
        self.subset_fraction = subset_fraction  # é è¨­ä½¿ç”¨ 2% è³‡æ–™

    def create_dataset(self) -> Dataset:
        print(f"è¼‰å…¥è³‡æ–™æª”æ¡ˆï¼š{self.file_path}")

        try:
            df = pd.read_csv(self.file_path)
        except FileNotFoundError:
            print("âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼Œå˜—è©¦ä½¿ç”¨å‚™ç”¨è·¯å¾‘...")
            alternative_path = "output/final_audio_paths_zh.csv"
            df = pd.read_csv(alternative_path)
            print(f"âœ… ä½¿ç”¨å‚™ç”¨æª”æ¡ˆï¼š{alternative_path}")

        # ä½¿ç”¨æ¥µå°çš„è³‡æ–™å­é›†ä»¥é¿å…è¨˜æ†¶é«”å•é¡Œ
        subset_size = max(50, int(len(df) * self.subset_fraction))  # è‡³å°‘ 50 å€‹æ¨£æœ¬
        print(f"å®Œæ•´è³‡æ–™é›†å¤§å°ï¼š{len(df)}")
        print(f"ä½¿ç”¨è³‡æ–™é›†å¤§å°ï¼š{subset_size} ({(subset_size/len(df)*100):.1f}%)")

        # éš¨æ©Ÿå–æ¨£
        subset_data = df.sample(n=subset_size, random_state=42).reset_index(drop=True)

        # æ¸…ç†åŸå§‹è³‡æ–™
        del df
        gc.collect()

        dataset = Dataset.from_pandas(subset_data)
        dataset = dataset.cast_column(
            "file", Audio(sampling_rate=self.target_sampling_rate)
        )
        dataset = dataset.rename_column("file", "audio")

        return dataset


# ==============================================================================
# ä¸»åŸ·è¡Œæµç¨‹
# ==============================================================================


def main():
    print("=== Breeze ASR è¨˜æ†¶é«”å®‰å…¨è¨“ç·´ç‰ˆæœ¬ ===")
    print("ğŸ›¡ï¸  é‡å° CUDA OOM å•é¡Œçš„å¾¹åº•è§£æ±ºæ–¹æ¡ˆ")

    # --- åƒæ•¸è¨­å®š ---
    CSV_PATH = "output_zh_optimized_v2.csv"
    MODEL_NAME = "MediaTek-Research/Breeze-ASR-25"
    LANGUAGE = "zh"
    TASK = "transcribe"
    OUTPUT_DIR = "./whisper-small-zh-finetune-memory-safe"

    print(f"æ¨¡å‹ï¼š{MODEL_NAME}")
    print(f"è¼¸å‡ºç›®éŒ„ï¼š{OUTPUT_DIR}")

    # åˆå§‹è¨˜æ†¶é«”æ¸…ç†
    aggressive_memory_cleanup()
    check_memory_usage()

    try:
        # --- è¼‰å…¥ Processor å’Œæ¨¡å‹ ---
        print("\n--- æ­¥é©Ÿ 1/4: è¼‰å…¥ Processor å’Œæ¨¡å‹ ---")
        processor = WhisperProcessor.from_pretrained(
            MODEL_NAME, language=LANGUAGE, task=TASK
        )
        print("âœ… Processor è¼‰å…¥æˆåŠŸ")

        check_memory_usage()

        # è¼‰å…¥æ¨¡å‹æ™‚ä½¿ç”¨è¨˜æ†¶é«”å„ªåŒ–é…ç½®
        model = WhisperForConditionalGeneration.from_pretrained(
            MODEL_NAME,
            torch_dtype=torch.float16,  # ä½¿ç”¨åŠç²¾åº¦ç¯€çœè¨˜æ†¶é«”
            device_map="auto",
            low_cpu_mem_usage=True,
            use_cache=False,  # é—œé–‰å¿«å–ä»¥ç¯€çœè¨˜æ†¶é«”
        )
        print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")

        # é…ç½®æ¨¡å‹
        model.config.forced_decoder_ids = None
        model.config.suppress_tokens = []
        model.config.use_cache = False

        check_memory_usage()

        # --- å»ºç«‹è¨˜æ†¶é«”å®‰å…¨è³‡æ–™é›† ---
        print("\n--- æ­¥é©Ÿ 2/4: å»ºç«‹è¨˜æ†¶é«”å®‰å…¨è³‡æ–™é›† (2% è³‡æ–™) ---")
        audio_processor = MemorySafeDatasetProcessor(
            file_path=CSV_PATH, subset_fraction=0.02  # ä½¿ç”¨ 2% çš„è³‡æ–™
        )

        dataset = audio_processor.create_dataset()
        print(f"è³‡æ–™é›†å»ºç«‹å®Œæˆï¼Œæ¨£æœ¬æ•¸ï¼š{len(dataset)}")

        # åˆ†å‰²è¨“ç·´å’Œæ¸¬è©¦é›†
        common_voice = dataset.train_test_split(test_size=0.2, seed=42)
        print(f"è¨“ç·´é›†ï¼š{len(common_voice['train'])} æ¨£æœ¬")
        print(f"æ¸¬è©¦é›†ï¼š{len(common_voice['test'])} æ¨£æœ¬")

        # è¨­å®šå³æ™‚è½‰æ›
        prepare_fn = partial(
            prepare_dataset_memory_safe,
            feature_extractor=processor.feature_extractor,
            tokenizer=processor.tokenizer,
        )
        vectorized_datasets = common_voice.with_transform(prepare_fn)
        print("å³æ™‚è½‰æ›å·²è¨­å®š")

        check_memory_usage()

        # --- å»ºç«‹è¨“ç·´å…ƒä»¶ ---
        print("\n--- æ­¥é©Ÿ 3/4: å»ºç«‹è¨˜æ†¶é«”å®‰å…¨è¨“ç·´å…ƒä»¶ ---")
        data_collator = MemorySafeDataCollator(processor=processor)
        compute_metrics_fn = partial(
            compute_metrics_safe, tokenizer=processor.tokenizer
        )

        # æ¥µåº¦ä¿å®ˆçš„è¨“ç·´åƒæ•¸
        training_args = Seq2SeqTrainingArguments(
            output_dir=OUTPUT_DIR,
            # æœ€å°è¨˜æ†¶é«”é…ç½®
            per_device_train_batch_size=1,  # æœ€å°æ‰¹æ¬¡
            per_device_eval_batch_size=1,  # æœ€å°è©•ä¼°æ‰¹æ¬¡
            gradient_accumulation_steps=8,  # è¼ƒå°çš„ç´¯ç©æ­¥æ•¸
            # é—œé–‰æ‰€æœ‰å¯èƒ½çš„è¨˜æ†¶é«”æ¶ˆè€—
            dataloader_num_workers=0,  # é—œé–‰å¤šé€²ç¨‹
            dataloader_pin_memory=False,  # é—œé–‰ pin memory
            # ä¿å®ˆçš„å­¸ç¿’åƒæ•¸
            learning_rate=5e-6,  # éå¸¸å°çš„å­¸ç¿’ç‡
            warmup_steps=10,  # æœ€å°‘æš–èº«æ­¥æ•¸
            max_steps=100,  # æ¥µå°‘çš„è¨“ç·´æ­¥æ•¸ï¼Œå…ˆç¢ºä¿èƒ½é‹è¡Œ
            # è¨˜æ†¶é«”å„ªåŒ–
            gradient_checkpointing=False,  # é—œé–‰æ¢¯åº¦æª¢æŸ¥é»
            fp16=True,  # ä½¿ç”¨åŠç²¾åº¦
            # æœ€å°‘çš„è©•ä¼°å’Œä¿å­˜
            eval_strategy="steps",
            predict_with_generate=True,
            generation_max_length=128,  # ç¸®çŸ­ç”Ÿæˆé•·åº¦
            save_steps=50,  # é »ç¹ä¿å­˜
            eval_steps=50,  # é »ç¹è©•ä¼°
            logging_steps=5,  # é »ç¹è¨˜éŒ„
            # é—œé–‰ä¸å¿…è¦çš„åŠŸèƒ½
            report_to=[],  # é—œé–‰æ‰€æœ‰å ±å‘Š
            load_best_model_at_end=False,  # é—œé–‰æœ€ä½³æ¨¡å‹è¼‰å…¥
            save_total_limit=1,  # åªä¿ç•™1å€‹æª¢æŸ¥é»
            # å…¶ä»–å„ªåŒ–
            remove_unused_columns=False,
            optim="adamw_torch",
        )

        # å»ºç«‹è¨“ç·´å™¨
        trainer = Seq2SeqTrainer(
            args=training_args,
            model=model,
            train_dataset=vectorized_datasets["train"],
            eval_dataset=vectorized_datasets["test"],
            data_collator=data_collator,
            compute_metrics=compute_metrics_fn,
            tokenizer=processor.feature_extractor,
        )

        check_memory_usage()

        # --- é–‹å§‹è¨˜æ†¶é«”å®‰å…¨è¨“ç·´ ---
        print("\n--- æ­¥é©Ÿ 4/4: é–‹å§‹è¨˜æ†¶é«”å®‰å…¨å¾®èª¿è¨“ç·´ ---")
        print("ğŸš€ é æœŸè¨“ç·´æ™‚é–“ï¼š5-10 åˆ†é˜")
        print("ğŸ’¡ ä½¿ç”¨æ¥µå°æ‰¹æ¬¡å’Œæ¥µå°‘æ­¥æ•¸ç¢ºä¿ç©©å®šæ€§")

        # è¨“ç·´å‰æœ€å¾Œä¸€æ¬¡è¨˜æ†¶é«”æ¸…ç†
        aggressive_memory_cleanup()
        check_memory_usage()

        # é–‹å§‹è¨“ç·´
        trainer.train()
        print("\nâœ… è¨˜æ†¶é«”å®‰å…¨è¨“ç·´å®Œæˆ")

        # --- å„²å­˜æ¨¡å‹ ---
        print("\n--- å„²å­˜è¨“ç·´å®Œæˆçš„æ¨¡å‹ ---")
        trainer.save_model(OUTPUT_DIR)
        processor.save_pretrained(OUTPUT_DIR)
        print(f"æ¨¡å‹å·²å„²å­˜è‡³ï¼š{OUTPUT_DIR}")

        # --- é¡¯ç¤ºè¨“ç·´çµæœæ‘˜è¦ ---
        print("\n=== è¨˜æ†¶é«”å®‰å…¨è¨“ç·´æ‘˜è¦ ===")
        print(f"ä½¿ç”¨è³‡æ–™é‡ï¼š2% ({len(dataset)} æ¨£æœ¬)")
        print(f"è¨“ç·´æ­¥æ•¸ï¼š100 æ­¥")
        print(f"æ‰¹æ¬¡è¨­å®šï¼šbatch_size=1, accumulation=8")
        print("ç‹€æ…‹ï¼šæˆåŠŸå®Œæˆï¼Œæ²’æœ‰è¨˜æ†¶é«”éŒ¯èª¤")

    except torch.cuda.OutOfMemoryError as e:
        print(f"\nâŒ ä»ç„¶é‡åˆ°è¨˜æ†¶é«”ä¸è¶³ï¼š{e}")
        print("ğŸ’¡ å»ºè­°ï¼š")
        print("1. é‡å•Ÿ Python ç’°å¢ƒæˆ–é›»è…¦")
        print("2. é—œé–‰æ‰€æœ‰å…¶ä»–ç¨‹å¼")
        print("3. è€ƒæ…®ä½¿ç”¨ CPU è¨“ç·´")
        aggressive_memory_cleanup()

    except Exception as e:
        print(f"\nâŒ å…¶ä»–éŒ¯èª¤ï¼š{e}")
        aggressive_memory_cleanup()
        raise e

    finally:
        # æœ€çµ‚æ¸…ç†
        aggressive_memory_cleanup()
        print("ğŸ§¹ åŸ·è¡Œæœ€çµ‚è¨˜æ†¶é«”æ¸…ç†")


if __name__ == "__main__":
    main()
